{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d95e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e18ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.13.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/emmanuel/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.5.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.14.1+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.5\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.1\n",
      "transformers version: 4.28.1\n",
      "mlflow version: 1.30.1\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import concurrent.futures\n",
    "\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "\n",
    "import monai.losses as losses\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.networks.layers import Norm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import Transform\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    SpatialPad,\n",
    "    SpatialPadd,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    NormalizeIntensity,\n",
    "    NormalizeIntensityd,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    "    RandGaussianNoised,\n",
    ")\n",
    "\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    SmartCacheDataset,\n",
    "    PersistentDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR\n",
    "\n",
    "from boundary_loss import BDLoss, DC_and_BD_loss\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27ce420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model/best_metric_model_with_boundry_loss.pth\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = 'Model'\n",
    "model_name =  os.path.join(root_dir, \"best_metric_model_with_boundry_loss.pth\")\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced24050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineBinaryMaps(Transform):\n",
    "    def __init__(self, num_classes, keys):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, data):\n",
    "        binary_maps = data[\"label\"]\n",
    "        combined_map = torch.zeros_like(data['image'][0])\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            zero_indices = np.where(combined_map == 0)\n",
    "            combined_map[zero_indices] += (i + 1) * binary_maps[i][zero_indices]\n",
    "#             combined_map %= (self.num_classes + 1)\n",
    "\n",
    "        data[\"label\"] = combined_map.long().unsqueeze(0)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ab7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataReader(Transform):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Load data from the data_dir\n",
    "        file_path = os.path.join(self.data_dir, img)\n",
    "        loaded_data = np.load(file_path)  # Customize this to your specific data format\n",
    "\n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891f3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 4\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ToDo: Try windowing with W:350 and L:40\n",
    "# define the window width and level\n",
    "window_width = 350\n",
    "window_level = 40\n",
    "\n",
    "# calculate the intensity range to clip\n",
    "intensity_min = window_level - window_width / 2.0\n",
    "intensity_max = window_level + window_width / 2.0\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True, image_only=False),\n",
    "        CombineBinaryMaps(keys=[\"label\"], num_classes=10),\n",
    "#         RandGaussianNoised(keys=[\"image\"], prob=0.50, mean=0.0, std=0.1),\n",
    "\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        SpatialPadd(\n",
    "            spatial_size=(96, 96, 96),\n",
    "            keys=[\"image\", \"label\"]\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=False),\n",
    "       \n",
    "#         RandCropByLabelClassesd(\n",
    "#             keys=[\"image\", \"label\"],\n",
    "#             label_key=\"label\",\n",
    "#             spatial_size=(96, 96, 96),\n",
    "#             num_samples=num_samples,\n",
    "#             num_classes=11,\n",
    "#             image_key=\"image\",\n",
    "#             image_threshold=0,\n",
    "#             allow_smaller=True\n",
    "#         ),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=num_samples,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "            allow_smaller=True\n",
    "        ),\n",
    "\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True, image_only=False),\n",
    "        CombineBinaryMaps(keys=[\"label\"], num_classes=10),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        SpatialPadd(\n",
    "            spatial_size=(96, 96, 96),\n",
    "            keys=[\"image\", \"label\"]\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9797df2",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdad2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_path(root_path):\n",
    "    all_files = os.listdir(root_path)\n",
    "    return [{'image': f'{root_path}/{i}/ct.nii.gz',\n",
    "             'label': [f'{root_path}/{i}/segments/{f}' for f in os.listdir(f'{root_path}/{i}/segments')],\n",
    "#              'label': f'{root_path}/{i}/labels.nii.gz'\n",
    "\n",
    "            } \n",
    "            for i in all_files if os.path.isfile(f'{root_path}/{i}/ct.nii.gz')]\n",
    "\n",
    "def data_reader(file_addr):\n",
    "    # load the image data\n",
    "    image_read = nib.load(item[\"image\"])\n",
    "    image_data = image_read.get_fdata(dtype=np.float32)\n",
    "    header = image_read.header\n",
    "    # load the label data\n",
    "    label_data = nib.load(item[\"label\"]).get_fdata(dtype=np.float32)\n",
    "    # Extract the metadata from the header\n",
    "    metadata = {'dim': header.get_data_shape(),\n",
    "                'pixdim': header.get_zooms(),\n",
    "                'affine': header.get_qform()}\n",
    "    data = {\n",
    "        'image': image_data,\n",
    "        'label': label_data,\n",
    "        'metadata': metadata,\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b35b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'Dataset'\n",
    "file_list_train = generate_file_path(root_path=f'{root}/train')\n",
    "file_list_val = generate_file_path(root_path=f'{root}/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12093c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    transform = SpatialPad(\n",
    "            (96, 96, 96),\n",
    "        )\n",
    "#     print([item for item in batch[0]])\n",
    "    images = [transform(item[\"image\"]) for item in batch[0]]\n",
    "    labels = [transform(item[\"label\"]) for item in batch[0]]\n",
    "#     print(images.shape, labels.shape)\n",
    "    return {\"image\": torch.stack(images),\n",
    "           \"label\":torch.stack(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ba7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PersistentDataset(\n",
    "    data=file_list_train,\n",
    "    transform=train_transforms,\n",
    "    cache_dir='train_unet'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True,\n",
    "                                collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96))\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af87b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = PersistentDataset(\n",
    "    data=file_list_val,\n",
    "    transform=val_transforms,\n",
    "    cache_dir='val'\n",
    "#     cache_dir='C:/Training/val'\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=1, \n",
    "                              collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff890e5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0a8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        else:\n",
    "            if (self.best_loss - loss) > self.min_delta:\n",
    "                self.best_loss = loss\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                print(f'Early Stopping patience: {self.counter}, best loss: {self.best_loss}, current_loss: {loss}')\n",
    "                if self.counter >= self.tolerance:  \n",
    "                    self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6c1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU found, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d51d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = UNet(\n",
    "              spatial_dims=3,\n",
    "              in_channels=1,\n",
    "              out_channels=11,\n",
    "              channels=(16, 32, 64, 128, 256),\n",
    "              strides=(2, 2, 2, 2),\n",
    "              num_res_units=2,\n",
    "              norm=Norm.BATCH\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b75b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "early_stopping = EarlyStopping(tolerance=10, min_delta=0.001)\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True, lambda_dice=1, lambda_ce=1)\n",
    "bd_loss =  BDLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10, verbose=True, mode='min', min_lr=1e-8, factor=0.9)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c967d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SpatialPad(\n",
    "            (1, 96, 96, 96),\n",
    "        )\n",
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "#     model.to('cpu')\n",
    "    validation_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "#             with torch.cuda.amp.autocast():\n",
    "            val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), num_samples, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            loss = loss_function(val_outputs, val_labels).item()\n",
    "            \n",
    "            val_out_convert = torch.stack(val_labels_convert)\n",
    "            \n",
    "            print(\"type val_out_convert => \", type(val_out_convert))\n",
    "            print(\"dir val_out_convert => \", dir(val_out_convert))\n",
    "            \n",
    "            \n",
    "            val_labels_convert = torch.stack(val_labels_convert)\n",
    "            boundry_loss = bd_loss(val_output_convert,val_labels_convert)\n",
    "            loss += 0.5 * boundry_loss.item()\n",
    "\n",
    "            validation_loss.append(loss.item())\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            del val_output_convert, val_labels_convert, val_outputs\n",
    "#             epoch_iterator_val.set_description(f\"Validate (loss={loss.item():2.5f})\")\n",
    "            epoch_iterator_val.set_description(f\"Validate (loss={loss:2.5f}) (boundry_loss={0.5 * boundry_loss.item():2.5f})\")\n",
    "#             break\n",
    "            break\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "#         val_inputs, val_labels = val_inputs.cpu(), val_labels.cpu()\n",
    "        mean_hausdorff = 0\n",
    "\n",
    "        validation_loss_mean = np.nanmean(np.nan_to_num(np.array(validation_loss),\n",
    "                                               nan=np.nan, posinf=np.nan, neginf=np.nan))\n",
    "\n",
    "        val_loss_values.append(validation_loss_mean)\n",
    "    return mean_dice_val, mean_hausdorff, validation_loss_mean\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "#         print(step)\n",
    "        x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "#         a = all(t.shape == x.shape for t in y)\n",
    "        if x.shape != y.shape:\n",
    "            print(x.shape, y.shape)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logit_map = model(x)\n",
    "            loss = loss_function(logit_map, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        epoch_loss += loss.item()\n",
    "        if torch.isnan(loss):\n",
    "            print(torch.max(x), torch.min(x))\n",
    "            \n",
    "        scaler.unscale_(optimizer)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_iterator.set_description(f\"Training ({global_step} / {max_iterations} Steps) (loss={loss.item():2.5f})\")\n",
    "        global_step += 1\n",
    "        break\n",
    "       \n",
    "\n",
    "    epoch_loss /= step\n",
    "    return global_step, dice_val_best, global_step_best, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38b6f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 90000 Steps) (loss=1.98131):   0%|                                                                                                                                                   | 0/357 [00:00<?, ?it/s]\n",
      "Validate:   0%|                                                                                                                                                                                     | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type val_out_convert =>  <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "dir val_out_convert =>  ['H', 'T', '__abs__', '__add__', '__and__', '__array__', '__array_function__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__cuda_array_interface__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__dlpack__', '__dlpack_device__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__torch_dispatch__', '__torch_function__', '__truediv__', '__weakref__', '__xor__', '_addmm_activation', '_applied_operations', '_autocast_to_full_precision', '_autocast_to_reduced_precision', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_conj', '_conj_physical', '_convert', '_dimI', '_dimV', '_fix_weakref', '_grad', '_grad_fn', '_has_symbolic_sizes_strides', '_indices', '_is_batch', '_is_view', '_is_zerotensor', '_make_subclass', '_make_wrapper_subclass', '_meta', '_neg_view', '_nested_tensor_layer_norm', '_nested_tensor_size', '_nnz', '_pending_operations', '_python_dispatch', '_reduce_ex_internal', '_storage', '_to_dense', '_update_names', '_values', '_version', 'abs', 'abs_', 'absolute', 'absolute_', 'acos', 'acos_', 'acosh', 'acosh_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'adjoint', 'affine', 'align_as', 'align_to', 'all', 'allclose', 'amax', 'amin', 'aminmax', 'angle', 'any', 'applied_operations', 'apply_', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan2', 'arctan2_', 'arctan_', 'arctanh', 'arctanh_', 'argmax', 'argmin', 'argsort', 'argwhere', 'array', 'as_dict', 'as_strided', 'as_strided_', 'as_strided_scatter', 'as_subclass', 'as_tensor', 'asin', 'asin_', 'asinh', 'asinh_', 'astype', 'atan', 'atan2', 'atan2_', 'atan_', 'atanh', 'atanh_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bfloat16', 'bincount', 'bitwise_and', 'bitwise_and_', 'bitwise_left_shift', 'bitwise_left_shift_', 'bitwise_not', 'bitwise_not_', 'bitwise_or', 'bitwise_or_', 'bitwise_right_shift', 'bitwise_right_shift_', 'bitwise_xor', 'bitwise_xor_', 'bmm', 'bool', 'broadcast_to', 'byte', 'cauchy_', 'ccol_indices', 'cdouble', 'ceil', 'ceil_', 'cfloat', 'chalf', 'char', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clear_pending_operations', 'clip', 'clip_', 'clone', 'coalesce', 'col_indices', 'conj', 'conj_physical', 'conj_physical_', 'contiguous', 'copy_', 'copy_items', 'copy_meta_from', 'copysign', 'copysign_', 'corrcoef', 'cos', 'cos_', 'cosh', 'cosh_', 'count_nonzero', 'cov', 'cpu', 'cross', 'crow_indices', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumprod_', 'cumsum', 'cumsum_', 'data', 'data_ptr', 'deg2rad', 'deg2rad_', 'dense_dim', 'dequantize', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'diagonal_scatter', 'diff', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'divide', 'divide_', 'dot', 'double', 'dsplit', 'dtype', 'eig', 'element_size', 'ensure_torch_and_prune_meta', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp2', 'exp2_', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fill_', 'fill_diagonal_', 'fix', 'fix_', 'flatten', 'flatten_meta_objs', 'flip', 'fliplr', 'flipud', 'float', 'float_power', 'float_power_', 'floor', 'floor_', 'floor_divide', 'floor_divide_', 'fmax', 'fmin', 'fmod', 'fmod_', 'frac', 'frac_', 'frexp', 'gather', 'gcd', 'gcd_', 'ge', 'ge_', 'geometric_', 'geqrf', 'ger', 'get_array', 'get_default_affine', 'get_default_applied_operations', 'get_default_meta', 'get_device', 'grad', 'grad_fn', 'greater', 'greater_', 'greater_equal', 'greater_equal_', 'gt', 'gt_', 'half', 'hardshrink', 'has_names', 'heaviside', 'heaviside_', 'histc', 'histogram', 'hsplit', 'hypot', 'hypot_', 'i0', 'i0_', 'igamma', 'igamma_', 'igammac', 'igammac_', 'imag', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_reduce', 'index_reduce_', 'index_select', 'indices', 'inner', 'int', 'int_repr', 'inverse', 'ipu', 'is_batch', 'is_coalesced', 'is_complex', 'is_conj', 'is_contiguous', 'is_cpu', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_inference', 'is_ipu', 'is_leaf', 'is_meta', 'is_mkldnn', 'is_mps', 'is_neg', 'is_nested', 'is_nonzero', 'is_ort', 'is_pinned', 'is_quantized', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'is_sparse_csr', 'is_vulkan', 'is_xpu', 'isclose', 'isfinite', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'item', 'kron', 'kthvalue', 'layout', 'lcm', 'lcm_', 'ldexp', 'ldexp_', 'le', 'le_', 'lerp', 'lerp_', 'less', 'less_', 'less_equal', 'less_equal_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_and_', 'logical_not', 'logical_not_', 'logical_or', 'logical_or_', 'logical_xor', 'logical_xor_', 'logit', 'logit_', 'logsumexp', 'long', 'lstsq', 'lt', 'lt_', 'lu', 'lu_solve', 'mH', 'mT', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_exp', 'matrix_power', 'max', 'maximum', 'mean', 'median', 'meta', 'min', 'minimum', 'mm', 'mode', 'moveaxis', 'movedim', 'msort', 'mul', 'mul_', 'multinomial', 'multiply', 'multiply_', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'names', 'nan_to_num', 'nan_to_num_', 'nanmean', 'nanmedian', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'ndim', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'negative', 'negative_', 'nelement', 'new', 'new_empty', 'new_empty_strided', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nextafter', 'nextafter_', 'nonzero', 'norm', 'normal_', 'not_equal', 'not_equal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'outer', 'output_nr', 'peek_pending_affine', 'peek_pending_shape', 'pending_operations', 'permute', 'pin_memory', 'pinverse', 'pixdim', 'polygamma', 'polygamma_', 'pop_applied_operation', 'pop_pending_operation', 'positive', 'pow', 'pow_', 'prelu', 'print_verbose', 'prod', 'push_applied_operation', 'push_pending_operation', 'put', 'put_', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qr', 'qscheme', 'quantile', 'rad2deg', 'rad2deg_', 'random_', 'ravel', 'real', 'reciprocal', 'reciprocal_', 'record_stream', 'refine_names', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'rename', 'rename_', 'renorm', 'renorm_', 'repeat', 'repeat_interleave', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'resize_as_sparse_', 'resolve_conj', 'resolve_neg', 'retain_grad', 'retains_grad', 'roll', 'rot90', 'round', 'round_', 'row_indices', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'scatter_reduce', 'scatter_reduce_', 'select', 'select_scatter', 'set_', 'set_array', 'sgn', 'sgn_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'signbit', 'sin', 'sin_', 'sinc', 'sinc_', 'sinh', 'sinh_', 'size', 'slice_scatter', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'subtract', 'subtract_', 'sum', 'sum_to_size', 'svd', 'swapaxes', 'swapaxes_', 'swapdims', 'swapdims_', 'symeig', 't', 't_', 'take', 'take_along_dim', 'tan', 'tan_', 'tanh', 'tanh_', 'tensor_split', 'tile', 'to', 'to_dense', 'to_mkldnn', 'to_padded_tensor', 'to_sparse', 'to_sparse_bsc', 'to_sparse_bsr', 'to_sparse_coo', 'to_sparse_csc', 'to_sparse_csr', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'triangular_solve', 'tril', 'tril_', 'triu', 'triu_', 'true_divide', 'true_divide_', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unflatten', 'unfold', 'uniform_', 'unique', 'unique_consecutive', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_', 'update_meta', 'values', 'var', 'vdot', 'view', 'view_as', 'vsplit', 'where', 'xlogy', 'xlogy_', 'xpu', 'zero_']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12943/3360597351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_val_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_val_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mepoch_iterator_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_ncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdice_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhausdorff_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepoch_loss_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12943/944809171.py\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(epoch_iterator_val)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mval_labels_convert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mboundry_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_output_convert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_labels_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mboundry_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/pythonProject/boundary_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, net_output, gt)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mbound\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprecomputed\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mnet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/pythonProject/boundary_loss.py\u001b[0m in \u001b[0;36msoftmax_helper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/nd_softmax.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mrpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "max_iterations = 90000\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=11)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=11)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=True, get_not_nans=False, reduction=\"none\",\n",
    "                                           distance_metric=\"euclidean\")\n",
    "# remove this section future run\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "val_loss_values = []\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best, epoch_loss = train(global_step, train_loader, dice_val_best, global_step_best)\n",
    "    epoch_iterator_val = tqdm(val_loader, desc=\"Validate\", dynamic_ncols=True)\n",
    "    dice_val, hausdorff_val, loss_val = validation(epoch_iterator_val)\n",
    "    scheduler.step(epoch_loss)\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    metric_values.append(dice_val)\n",
    "    early_stopping(loss_val)\n",
    "    print(f'Mean Hausdorff disatnce: {hausdorff_val}')\n",
    "    if dice_val > dice_val_best:\n",
    "        dice_val_best = dice_val\n",
    "        global_step_best = global_step\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        print(\n",
    "            \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val)\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                dice_val_best, dice_val\n",
    "            )\n",
    "        )\n",
    "    # early stopping\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "        \n",
    "model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_iterator_val = tqdm(val_loader, desc=\"Validate\", dynamic_ncols=True)\n",
    "# for batch in epoch_iterator_val:\n",
    "#  print(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e90e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc083e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_num = 357\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Iteration Average Loss\")\n",
    "x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y, label='Train')\n",
    "x = [eval_num * (i + 1) for i in range(len(val_loss_values))]\n",
    "y = val_loss_values\n",
    "plt.plot(x, y, label='Validation')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_num = 4\n",
    "with torch.no_grad():\n",
    "    model.to('cpu')\n",
    "    img_name = os.path.split(val_ds[case_num][\"image\"].meta[\"filename_or_obj\"])[1]\n",
    "    img = val_ds[case_num][\"image\"]\n",
    "    label = val_ds[case_num][\"label\"]\n",
    "    val_inputs = torch.unsqueeze(img, 1).cpu()\n",
    "    val_labels = torch.unsqueeze(label, 1).cpu()\n",
    "    val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), num_samples, model, overlap=0.8)\n",
    "    plt.figure(\"check\", (18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, 200], cmap=\"gray\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"label\")\n",
    "    plt.imshow(val_labels.cpu().numpy()[0, 0, :, :, 200])\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"output\")\n",
    "    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, 200])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_test = generate_file_path(root_path=f'{root}/test')\n",
    "test_ds = PersistentDataset(\n",
    "    data=file_list_test,\n",
    "    transform=val_transforms,\n",
    "    cache_dir='test'\n",
    "#     cache_dir='C:/Training/val'\n",
    ")\n",
    "\n",
    "test_loader = ThreadDataLoader(test_ds, num_workers=0, batch_size=1, \n",
    "                              collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d179da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch_iterator_test):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_test:\n",
    "            test_inputs, test_labels = (batch[\"image\"].cpu(), batch[\"label\"].cpu())\n",
    "            with torch.cuda.amp.autocast():\n",
    "#                 test_outputs = sliding_window_inference(test_inputs, (96, 96, 96), num_samples, model, overlap=0.8)\n",
    "                test_outputs = sliding_window_inference(test_inputs, (96, 96, 96), num_samples, model)\n",
    "            test_labels_list = decollate_batch(test_labels)\n",
    "            test_labels_convert = [post_label(test_label_tensor) for test_label_tensor in test_labels_list]\n",
    "            test_outputs_list = decollate_batch(test_outputs)\n",
    "            test_output_convert = [post_pred(test_pred_tensor) for test_pred_tensor in test_outputs_list]\n",
    "            loss = loss_function(test_outputs, test_labels)\n",
    "            test_loss.append(loss.item())\n",
    "            dice_metric(y_pred=test_output_convert, y=test_labels_convert)\n",
    "            epoch_iterator_test.set_description(f\"Test (loss={loss.item():2.5f})\")\n",
    "        mean_dice_test = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "\n",
    "        test_loss_mean = np.nanmean(np.nan_to_num(np.array(test_loss),\n",
    "                                               nan=np.nan, posinf=np.nan, neginf=np.nan))\n",
    "    return mean_dice_test, test_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6863d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_iterator_test = tqdm(test_loader, desc=\"Test\", dynamic_ncols=True)\n",
    "dice_test, loss_test = test(epoch_iterator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test: (loss={loss_test}) (dice={dice_test})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2b866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
